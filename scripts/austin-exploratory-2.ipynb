{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ANONID', 'SUBJECT', 'CATALOG_NBR', 'GRD_PTS_PER_UNIT', 'GPAO', 'DIV',\n",
      "       'ANON_INSTR_ID', 'TERM'],\n",
      "      dtype='object')\n",
      "   ANONID SUBJECT  CATALOG_NBR  GRD_PTS_PER_UNIT      GPAO DIV  ANON_INSTR_ID  \\\n",
      "0      26     ACC          272               2.0  3.343636   P           2920   \n",
      "1     114     ACC          272               2.0  2.817857   P           2920   \n",
      "2     121     ACC          272               4.0  4.000000   P            201   \n",
      "3     125     ACC          272               1.3  3.639063   P           3360   \n",
      "4     180     ACC          272               3.0  3.846154   P           2920   \n",
      "5     207     ACC          272               2.0  2.715686   P           2920   \n",
      "6     224     ACC          272               3.0  3.591379   P           3604   \n",
      "7     249     ACC          272               3.0  3.334483   P           1914   \n",
      "8     356     ACC          272               4.0  3.655000   P           2640   \n",
      "9     400     ACC          272               3.3  3.650000   P           3360   \n",
      "\n",
      "   TERM  \n",
      "0    79  \n",
      "1    83  \n",
      "2   111  \n",
      "3    84  \n",
      "4   107  \n",
      "5    93  \n",
      "6    69  \n",
      "7   123  \n",
      "8   107  \n",
      "9    84  \n",
      "Index(['MAJOR3_DESCR', 'MAJOR2_DESCR', 'MAJOR1_DESCR', 'HSGPA',\n",
      "       'LAST_ACT_ENGL_SCORE', 'LAST_ACT_MATH_SCORE', 'LAST_ACT_READ_SCORE',\n",
      "       'LAST_ACT_SCIRE_SCORE', 'LAST_ACT_COMP_SCORE', 'LAST_SATI_VERB_SCORE',\n",
      "       'LAST_SATI_MATH_SCORE', 'LAST_SATI_TOTAL_SCORE', 'SEX', 'STDNT_GROUP1',\n",
      "       'STDNT_GROUP2', 'MAJOR1_DEPT', 'MAJOR2_DEPT', 'MAJOR3_DEPT', 'ANONID',\n",
      "       'ADMIT_TERM', 'MAJOR1_TERM', 'MAJOR2_TERM', 'MAJOR3_TERM',\n",
      "       'ADMIT_TERM_TERM_ID', 'ADMIT_TERM_TERM_DESCRIPTION',\n",
      "       'ADMIT_TERM_TERM_NAME', 'ADMIT_TERM_TERM_YEAR', 'MAJOR1_TERM_TERM_ID',\n",
      "       'MAJOR1_TERM_TERM_DESCRIPTION', 'MAJOR1_TERM_TERM_NAME',\n",
      "       'MAJOR1_TERM_TERM_YEAR', 'MAJOR2_TERM_TERM_ID',\n",
      "       'MAJOR2_TERM_TERM_DESCRIPTION', 'MAJOR2_TERM_TERM_NAME',\n",
      "       'MAJOR2_TERM_TERM_YEAR', 'MAJOR3_TERM_TERM_ID',\n",
      "       'MAJOR3_TERM_TERM_DESCRIPTION', 'MAJOR3_TERM_TERM_NAME',\n",
      "       'MAJOR3_TERM_TERM_YEAR'],\n",
      "      dtype='object')\n",
      "number of student records before exclusions 138888\n",
      "       MAJOR1_TERM_YEAR_MINUS_ADMIT_TERM_YEAR\n",
      "count                            91895.000000\n",
      "mean                                 3.708896\n",
      "std                                  1.380239\n",
      "min                                -28.000000\n",
      "25%                                  4.000000\n",
      "50%                                  4.000000\n",
      "75%                                  4.000000\n",
      "max                                 19.000000\n",
      "number of student records excluding students without graduation term 102550\n",
      "number of student records excluding extreme values 90678\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADMIT_TERM_TERM_YEAR</th>\n",
       "      <th>MAJOR1_TERM_TERM_YEAR</th>\n",
       "      <th>MAJOR2_TERM_TERM_YEAR</th>\n",
       "      <th>MAJOR3_TERM_TERM_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1998.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138880</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138881</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138882</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138885</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138887</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90678 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ADMIT_TERM_TERM_YEAR  MAJOR1_TERM_TERM_YEAR  MAJOR2_TERM_TERM_YEAR  \\\n",
       "1                     2008.0                 2012.0                    NaN   \n",
       "2                     1998.0                 2002.0                    NaN   \n",
       "3                     2007.0                 2012.0                    NaN   \n",
       "7                     2008.0                 2012.0                    NaN   \n",
       "8                     1998.0                 2001.0                 2001.0   \n",
       "...                      ...                    ...                    ...   \n",
       "138880                1999.0                 2003.0                    NaN   \n",
       "138881                2000.0                 2001.0                 2001.0   \n",
       "138882                2011.0                 2015.0                    NaN   \n",
       "138885                2005.0                 2009.0                    NaN   \n",
       "138887                2010.0                 2012.0                    NaN   \n",
       "\n",
       "        MAJOR3_TERM_TERM_YEAR  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3                         NaN  \n",
       "7                         NaN  \n",
       "8                         NaN  \n",
       "...                       ...  \n",
       "138880                    NaN  \n",
       "138881                 2001.0  \n",
       "138882                    NaN  \n",
       "138885                    NaN  \n",
       "138887                    NaN  \n",
       "\n",
       "[90678 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_course = pd.read_csv('../assets/student.course.csv')\n",
    "df_record = pd.read_csv('../assets/student.record.csv')\n",
    "df_term = pd.read_table('../assets/term.table.txt', delimiter=\"\\t\").fillna('Unknown')\n",
    "\n",
    "df_term.columns = ['TERM_ID', 'TERM_DESCRIPTION']\n",
    "\n",
    "terms = ['Fall', 'Winter', 'Summer', 'Spring', 'Unknown']\n",
    "df_term['TERM_NAME'] = df_term['TERM_DESCRIPTION'].apply(lambda x: list(filter(lambda y: y!='', [t if t in x else '' for t in terms]))[0])\n",
    "df_term['TERM_YEAR'] = df_term['TERM_DESCRIPTION'].apply(lambda x: int(x[-4:]) if x[-4:].isnumeric() else None)\n",
    "\n",
    "merge_course_df = pd.merge(\n",
    "                    df_course,\n",
    "                    df_term, \n",
    "                    how='left',\n",
    "                    left_on='TERM',\n",
    "                    right_on='TERM_ID')\n",
    "\n",
    "terms_student = ['ADMIT_TERM', 'MAJOR1_TERM', 'MAJOR2_TERM', 'MAJOR3_TERM']\n",
    "merge_record_df = df_record.copy()\n",
    "for term in terms_student:\n",
    "    \n",
    "    merge_record_df = pd.merge(\n",
    "                        merge_record_df,\n",
    "                        df_term, \n",
    "                        how='left',\n",
    "                        left_on=term,\n",
    "                        right_on='TERM_ID')\n",
    "    \n",
    "    merge_record_df.rename(columns={'TERM_ID': term + '_' + 'TERM_ID', \n",
    "                            'TERM_DESCRIPTION': term + '_' + 'TERM_DESCRIPTION', \n",
    "                            'TERM_NAME': term + '_' + 'TERM_NAME', \n",
    "                            'TERM_YEAR': term + '_' + 'TERM_YEAR'}, inplace=True)    \n",
    "\n",
    "# print unique df_course columns for reference \n",
    "print(df_course.columns)\n",
    "\n",
    "# Print and exammine the first ten records of course dataframe\n",
    "print(df_course.head(10))\n",
    "\n",
    "# Based on our use case questions and the data contained in df_course data, \n",
    "# df_course data was excluded from the analysis for the following reasons:\n",
    "# 1. Our use case is only concered with the volume of students by gender, graduation year, and major as compared to BLS workforce data\n",
    "# 2. Non of our use case questions are concerned with the courses students take, only the outcome of their major\n",
    "\n",
    "# print unique merge_record_df columns for reference \n",
    "print(merge_record_df.columns)\n",
    "\n",
    "# record_df is used because it contains the volume of students by gender, graduation year, and major as compared to BLS workforce data\n",
    "\n",
    "\n",
    "# Begin cleaning and manipulation of studet record data\n",
    "\n",
    "merge_record_df.sort_values(by=['MAJOR3_TERM_TERM_YEAR'], ascending=[True])['MAJOR3_TERM_TERM_YEAR'].unique()\n",
    "\n",
    "\n",
    "merge_record_df['ADMIT_TERM_EQUALS_MAJOR1_TERM'] = merge_record_df['ADMIT_TERM'] == merge_record_df['MAJOR1_TERM']\n",
    "merge_record_df['MAJOR1_TERM_YEAR_MINUS_ADMIT_TERM_YEAR'] = merge_record_df['MAJOR1_TERM_TERM_YEAR'] - merge_record_df['ADMIT_TERM_TERM_YEAR']\n",
    "\n",
    "# Take the count of all records before exclusions\n",
    "print('number of student records before exclusions', len(merge_record_df))\n",
    "print(merge_record_df[['ADMIT_TERM_EQUALS_MAJOR1_TERM', 'MAJOR1_TERM_YEAR_MINUS_ADMIT_TERM_YEAR']].describe())\n",
    "# The mean of the difference between the Major1 graduation term year and the admit term year is 3.7 years,\n",
    "# It is safe to assume that MAJOR1_TERM field is the graduation term of the student\n",
    "\n",
    "# Measure only the Students who have a Major1 graduation term\n",
    "merge_record_df = merge_record_df[merge_record_df.isnull()['MAJOR1_TERM'] == False]\n",
    "print('number of student records excluding students without graduation term', len(merge_record_df))\n",
    "\n",
    "# use box plot to identify outliers i.e. extreme values such as the -28 years minimum value as observed by describe() statistical function\n",
    "merge_record_df['MAJOR1_TERM_YEAR_MINUS_ADMIT_TERM_YEAR'].unique()\n",
    "\n",
    "# Exclude graduation terms with extreme values i.e. negative values\n",
    "merge_record_df = merge_record_df[(merge_record_df.isnull()['MAJOR1_TERM_YEAR_MINUS_ADMIT_TERM_YEAR'] == False)\\\n",
    "                                  & (merge_record_df['MAJOR1_TERM_YEAR_MINUS_ADMIT_TERM_YEAR'] >= 0)]\n",
    "\n",
    "print('number of student records excluding extreme values', len(merge_record_df))\n",
    "merge_record_df[['ADMIT_TERM_TERM_YEAR','MAJOR1_TERM_TERM_YEAR','MAJOR2_TERM_TERM_YEAR','MAJOR3_TERM_TERM_YEAR']]\n",
    "\n",
    "# There are 4 school terms:\n",
    "# - ADMIT_TERM: The term the student was admitted to the school\n",
    "# - MAJOR1_TERM: The term the student declared their first major\n",
    "# - MAJOR2_TERM: The term the student declared their first major\n",
    "# - MAJOR3_TERM: The term the student declared their first major\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "term = 'MAJOR1_TERM_TERM_YEAR' # ADMIT_TERM_TERM_YEAR'\n",
    "merge_record_df['MAJOR1_DESCR'] = merge_record_df['MAJOR1_DESCR'].fillna('Undeclared')\n",
    "df_majors = pd.read_excel('../assets/majors.xlsx', sheet_name='majors', header=0)\n",
    "\n",
    "df_record_occupation = pd.merge(merge_record_df,\n",
    "                            df_majors, \n",
    "                            how='left',\n",
    "                            left_on='MAJOR1_DESCR',\n",
    "                            right_on='MAJOR')\n",
    "\n",
    "df_record_occupation['number_of_students_all'] = 1\n",
    "df_record_occupation['number_of_students_men'] = df_record_occupation['SEX'].apply(lambda sex: 1 if sex == 'M' else 0) \n",
    "df_record_occupation['number_of_students_women'] = df_record_occupation['SEX'].apply(lambda sex: 1 if sex == 'F' else 0)\n",
    "df_record_occupation['number_of_students_unknown'] = df_record_occupation['SEX'].apply(lambda sex: 1 if sex not in ['M', 'F'] else 0)\n",
    "df_record_occupation['MAJOR1_TERM_TERM_YEAR'] = df_record_occupation['MAJOR1_TERM_TERM_YEAR'].apply(lambda x: str(x)[0:4])\n",
    "\n",
    "df_record_occupation_grouped = df_record_occupation.groupby(['OCCUPATION',term]).sum().reset_index()\n",
    "\n",
    "df_occupation_level_mapping = pd.read_excel('../assets/bls_cpsaat39_2011_to_2015.xlsx', sheet_name='level_mapping_l0', header=0)\n",
    "df_occupation_level_mapping_distinct = df_occupation_level_mapping[['l4', 'l3', 'l2', 'l1']].drop_duplicates().reset_index()\n",
    "df_occupation_level_mapping_distinct = df_occupation_level_mapping_distinct[['l4', 'l3', 'l2', 'l1']]\n",
    "\n",
    "df_record_occupation_level_grouped = pd.merge(df_record_occupation_grouped,\n",
    "                                                df_occupation_level_mapping_distinct, \n",
    "                                                how='left',\n",
    "                                                left_on='OCCUPATION',\n",
    "                                                right_on='l1')\n",
    "\n",
    "df_record_occupation_level_grouped = df_record_occupation_level_grouped[[term, 'OCCUPATION', 'number_of_students_all', \n",
    "                                                                        'number_of_students_men', 'number_of_students_women', \n",
    "                                                                        'number_of_students_unknown', 'l4', 'l3', 'l2', 'l1']].\\\n",
    "                                                                        sort_values(by=['OCCUPATION', term])\n",
    "\n",
    "df_record_occupation_level_grouped_by_year = df_record_occupation_level_grouped.groupby([term, 'l1']).sum().reset_index()\n",
    "df_record_occupation_level_grouped_by_year=df_record_occupation_level_grouped_by_year[[term, 'l4', 'l3', 'l2', 'l1', \n",
    "                                                                                      'number_of_students_all', 'number_of_students_men', \n",
    "                                                                                      'number_of_students_women', 'number_of_students_unknown']]\n",
    "df_record_occupation_level_grouped_by_year_filtered = df_record_occupation_level_grouped_by_year[df_record_occupation_level_grouped_by_year['MAJOR1_TERM_TERM_YEAR'].isin(['2011', '2012', '2013', '2014', '2015'])] \n",
    "# df_record_occupation_level_grouped_by_year_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "tabs = ['2015', '2014', '2013', '2012', '2011']\n",
    "\n",
    "df_bls_all = pd.DataFrame()\n",
    "for tab in tabs:\n",
    "    df_bls_next = pd.read_excel('../assets/bls_cpsaat39_2011_to_2015.xlsx', \n",
    "                                sheet_name=str(tab), \n",
    "                                header=0, \n",
    "                                ).fillna('Unknown')\n",
    "    df_bls_next['year'] = str(tab)\n",
    "    df_bls_all = pd.concat([df_bls_all, df_bls_next])\n",
    "\n",
    "\n",
    "df_level = pd.merge(df_bls_all,\n",
    "                    df_occupation_level_mapping, \n",
    "                    how='left',\n",
    "                    left_on='occupation',\n",
    "                    right_on='l0')\n",
    "\n",
    "df_level = df_level[df_level['l0'].notnull()]\n",
    "\n",
    "\n",
    "df_level['year'] = df_level['year'].apply(lambda x: str(x))\n",
    "\n",
    "df_level = df_level.groupby(['year', 'l1'], sort=True).agg({\n",
    "    'number_of_workers_all': 'sum',\n",
    "    'median_weekly_earnings_all': 'mean',\n",
    "    'number_of_workers_men': 'sum',\n",
    "    'median_weekly_earnings_men': 'mean',\n",
    "    'number_of_workers_women': 'sum',\n",
    "    'median_weekly_earnings_women': 'mean',\n",
    "    'occupation_x': 'first',\n",
    "    'occupation_y': 'first',\n",
    "    'l4': 'first',\n",
    "    'l3': 'first',\n",
    "    'l2': 'first',\n",
    "    'l0': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "df_merge_bls = pd.merge(df_level,\n",
    "                    df_record_occupation_level_grouped_by_year_filtered, \n",
    "                    how='left',\n",
    "                    left_on=['l1', 'year'],\n",
    "                    right_on=['l1', 'MAJOR1_TERM_TERM_YEAR'])[[\n",
    "                                'year', 'occupation_x', 'l0','l1','l2_x','l3_x','l4_x',                                    \n",
    "                                'number_of_workers_all', 'median_weekly_earnings_all',\n",
    "                                'number_of_workers_men', 'median_weekly_earnings_men',\n",
    "                                'number_of_workers_women', 'median_weekly_earnings_women',\n",
    "                                'number_of_students_all', 'number_of_students_men',\n",
    "                                'number_of_students_women', 'number_of_students_unknown'\n",
    "                    ]]\n",
    "\n",
    "new_column_names = {\n",
    "    'year': 'year',\n",
    "    'occupation_x': 'occupation',\n",
    "    'l0': 'l0',\n",
    "    'l1': 'l1',\n",
    "    'l2_x': 'l2',\n",
    "    'l3_x': 'l3',\n",
    "    'l4_x': 'l4',\n",
    "    'number_of_workers_all': 'number_of_workers_all_sum',\n",
    "    'median_weekly_earnings_all': 'median_weekly_earnings_all_mean',\n",
    "    'number_of_workers_men': 'number_of_workers_men_sum',\n",
    "    'median_weekly_earnings_men': 'median_weekly_earnings_men_mean',\n",
    "    'number_of_workers_women': 'number_of_workers_women_sum',\n",
    "    'median_weekly_earnings_women': 'median_weekly_earnings_women_mean',\n",
    "    'number_of_students_all': 'number_of_students_all_sum',\n",
    "    'number_of_students_men': 'number_of_students_men_sum',\n",
    "    'number_of_students_women': 'number_of_students_women_sum',\n",
    "    'number_of_students_unknown': 'number_of_students_unknown_sum'\n",
    "}\n",
    "\n",
    "\n",
    "df_merge_bls.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "df_merge_bls\n",
    "\n",
    "\n",
    "df_level_list = []\n",
    "selected_levels = ['l1','l2','l3']\n",
    "for level in selected_levels:\n",
    "    \n",
    "    df_merge_bls_level = df_merge_bls[[level, 'year',                              \n",
    "                        'number_of_students_all_sum',\n",
    "                        'number_of_students_men_sum', \n",
    "                        'number_of_students_women_sum', \n",
    "                        'number_of_students_unknown_sum',\n",
    "                        'number_of_workers_all_sum', \n",
    "                        'median_weekly_earnings_all_mean', \n",
    "                        'number_of_workers_men_sum', \n",
    "                        'median_weekly_earnings_men_mean', \n",
    "                        'number_of_workers_women_sum', \n",
    "                        'median_weekly_earnings_women_mean']\n",
    "                        ]\n",
    "\n",
    "    df_merge_bls_grouped = df_merge_bls_level.groupby(['year', level],  sort=True).sum().reset_index()\n",
    "    df_level_list.append(df_merge_bls_grouped)\n",
    "    df_merge_bls_grouped.to_csv('../scratch/df_merge_bls_'+ level + '.csv', index=False)\n",
    "    \n",
    "# df_level_list[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_short_names(level, metric) -> dict:\n",
    "    \n",
    "    short_names_dict = { \n",
    "        'l1': {\n",
    "            'default':{\n",
    "                'Architecture and engineering occupations' : 'Arch & Eng',\n",
    "                'Arts, design, entertainment, sports, and media occupations' : 'Ent',\n",
    "                'Building and grounds cleaning and maintenance occupations' : 'Maintenance',\n",
    "                'Business and financial operations occupations' : 'Financial',\n",
    "                'Community and social service occupations' : 'Social Services',\n",
    "                'Computer and mathematical occupations' : 'Comp & Math',\n",
    "                'Construction and extraction occupations' : 'Construction',\n",
    "                'Education, training, and library occupations' : 'Education',\n",
    "                'Farming, fishing, and forestry occupations' : 'Natural Resources',\n",
    "                'Food preparation and serving related occupations' : 'Food',\n",
    "                'Healthcare practitioners and technical occupations' : 'Healthcare Practitioners',\n",
    "                'Healthcare support occupations' : 'Healthcare',\n",
    "                'Installation, maintenance, and repair occupations' : 'Facilities',\n",
    "                'Legal occupations' : 'Legal',\n",
    "                'Life, physical, and social science occupations' : 'Science',\n",
    "                'Management occupations' : 'Management',\n",
    "                'Office and administrative support occupations' : 'Office Admin',\n",
    "                'Personal care and service occupations': 'Personal Care', \n",
    "                'Production occupations' : 'Production',\n",
    "                'Protective service occupations': 'Security', \n",
    "                'Sales and related occupations' : 'Sales',\n",
    "                'Transportation and material moving occupations' : 'Logistics'\n",
    "            },            \n",
    "            'number_of_workers':{\n",
    "                'Architecture and engineering occupations' : 'Arch & Eng',\n",
    "                'Arts, design, entertainment, sports, and media occupations' : 'Ent',\n",
    "                'Building and grounds cleaning and maintenance occupations' : 'Maintenance',\n",
    "                'Business and financial operations occupations' : 'Financial',\n",
    "                'Community and social service occupations' : 'Social Srvcs',\n",
    "                'Computer and mathematical occupations' : 'Comp & Math',\n",
    "                'Construction and extraction occupations' : 'Construction',\n",
    "                'Education, training, and library occupations' : 'Education',\n",
    "                'Farming, fishing, and forestry occupations' : 'Ntrl Rsrcs',\n",
    "                'Food preparation and serving related occupations' : 'Food',\n",
    "                'Healthcare practitioners and technical occupations' : 'Healthcare Practitioners',\n",
    "                'Healthcare support occupations' : 'Healthcare',\n",
    "                'Installation, maintenance, and repair occupations' : 'Facilities',\n",
    "                'Legal occupations' : 'Legal',\n",
    "                'Life, physical, and social science occupations' : 'Sci',\n",
    "                'Management occupations' : 'Management',\n",
    "                'Office and administrative support occupations' : 'Office Admin',\n",
    "                'Personal care and service occupations': 'Personal Care', \n",
    "                'Production occupations' : 'Production',\n",
    "                'Protective service occupations': 'Security', \n",
    "                'Sales and related occupations' : 'Sales',\n",
    "                'Transportation and material moving occupations' : 'Logistics'\n",
    "            },\n",
    "            'number_of_students':{\n",
    "                'Architecture and engineering occupations' : 'Arch & Eng',\n",
    "                'Arts, design, entertainment, sports, and media occupations' : 'Ent',\n",
    "                'Building and grounds cleaning and maintenance occupations' : 'Maintenance',\n",
    "                'Business and financial operations occupations' : 'Fin',\n",
    "                'Community and social service occupations' : 'Social Services',\n",
    "                'Computer and mathematical occupations' : 'Computer',\n",
    "                'Construction and extraction occupations' : 'Construction',\n",
    "                'Education, training, and library occupations' : 'Education',\n",
    "                'Farming, fishing, and forestry occupations' : 'Natural Resources',\n",
    "                'Food preparation and serving related occupations' : 'Food',\n",
    "                'Healthcare practitioners and technical occupations' : 'Med Pract',\n",
    "                'Healthcare support occupations' : 'Healthcare',\n",
    "                'Installation, maintenance, and repair occupations' : 'Facilities',\n",
    "                'Legal occupations' : 'Legal',\n",
    "                'Life, physical, and social science occupations' : 'Science',\n",
    "                'Management occupations' : 'Mgmt',\n",
    "                'Office and administrative support occupations' : 'Office Admin',\n",
    "                'Personal care and service occupations': 'Personal Care', \n",
    "                'Production occupations' : 'Production',\n",
    "                'Protective service occupations': 'Security', \n",
    "                'Sales and related occupations' : 'Sales',\n",
    "                'Transportation and material moving occupations' : 'Logistics'\n",
    "            },            \n",
    "        },\n",
    "        'l2': {\n",
    "            'default':{\n",
    "                'Building and grounds cleaning and maintenance occupations' : 'Maint',\n",
    "                'Construction and extraction occupations' : 'Construction',\n",
    "                'Farming, fishing, and forestry occupations' : 'Natural Resources',\n",
    "                'Food preparation and serving related occupations' : 'Food',\n",
    "                'Healthcare support occupations' : 'Health',\n",
    "                'Installation, maintenance, and repair occupations' : 'Facilities',\n",
    "                'Management, business, and financial operations occupations' : 'Business',\n",
    "                'Office and administrative support occupations' : 'Office Admin',\n",
    "                'Personal care and service occupations': 'Personal Care', \n",
    "                'Production occupations' : 'Production',\n",
    "                'Professional and related occupations' : 'Professional',\n",
    "                'Protective service occupations' : 'Security',\n",
    "                'Sales and related occupations' : 'Sales',\n",
    "                'Transportation and material moving occupations' : 'Logistics'\n",
    "            },            \n",
    "            'number_of_workers':{\n",
    "                'Building and grounds cleaning and maintenance occupations' : 'Maint',\n",
    "                'Construction and extraction occupations' : 'Construction',\n",
    "                'Farming, fishing, and forestry occupations' : 'Natural',\n",
    "                'Food preparation and serving related occupations' : 'Food',\n",
    "                'Healthcare support occupations' : 'Health',\n",
    "                'Installation, maintenance, and repair occupations' : 'Facilities',\n",
    "                'Management, business, and financial operations occupations' : 'Business',\n",
    "                'Office and administrative support occupations' : 'Office Admin',\n",
    "                'Personal care and service occupations': 'Personal Care', \n",
    "                'Production occupations' : 'Production',\n",
    "                'Professional and related occupations' : 'Professional',\n",
    "                'Protective service occupations' : 'Security',\n",
    "                'Sales and related occupations' : 'Sales',\n",
    "                'Transportation and material moving occupations' : 'Logistics'\n",
    "            },\n",
    "            'number_of_students':{\n",
    "                'Building and grounds cleaning and maintenance occupations' : 'Maint',\n",
    "                'Construction and extraction occupations' : 'Construction',\n",
    "                'Farming, fishing, and forestry occupations' : 'Natural Resources',\n",
    "                'Food preparation and serving related occupations' : 'Food',\n",
    "                'Healthcare support occupations' : 'Health',\n",
    "                'Installation, maintenance, and repair occupations' : 'Facilities',\n",
    "                'Management, business, and financial operations occupations' : 'Bus',\n",
    "                'Office and administrative support occupations' : 'Office',\n",
    "                'Personal care and service occupations': 'Personal Care', \n",
    "                'Production occupations' : 'Production',\n",
    "                'Professional and related occupations' : 'Professional',\n",
    "                'Protective service occupations' : 'Security',\n",
    "                'Sales and related occupations' : 'Sales',\n",
    "                'Transportation and material moving occupations' : 'Logistics'\n",
    "            },\n",
    "\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return short_names_dict[level][metric] if metric in short_names_dict[level].keys() else short_names_dict[level]['default']\n",
    "    \n",
    "from bokeh.palettes import Cividis256\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "def get_palette(number_of_groups) -> dict:\n",
    "\n",
    "    Cividis = {\n",
    "        'default': Cividis256[0:3] + Cividis256[64:67] + Cividis256[128:131]+ Cividis256[192: 195] + Cividis256[252: 255],\n",
    "        14: Cividis256[0:3] + Cividis256[64:67] + Cividis256[128:131]+ Cividis256[192: 195] + Cividis256[252: 255],\n",
    "        4: [Cividis256[0]] + [Cividis256[64]] + [Cividis256[192]] + [Cividis256[252]],\n",
    "        2: Cividis256[0]  + Cividis256[255]\n",
    "    }\n",
    "\n",
    "    return Cividis[number_of_groups] if number_of_groups in Cividis.keys() else Cividis['default']\n",
    "\n",
    "\n",
    "def get_format_parameters(metric, number_of_groups) -> dict:\n",
    "    \n",
    "    palette = get_palette(number_of_groups=number_of_groups)\n",
    "    print(number_of_groups,' - ', palette)\n",
    "    label_offset_dict = { \n",
    "        'default':{\n",
    "                'block':{'line_width': 1, \n",
    "                         'line_color': 'white', \n",
    "                         'fill_alpha': 0.80, \n",
    "                         'palette': palette},\n",
    "                'l2' : {'x_offset': 2, \n",
    "                        'y_offset': -35,\n",
    "                        'text_font_size': \"30pt\",\n",
    "                        'text_baseline': \"top\",\n",
    "                        'text_color': 'black'\n",
    "                        },\n",
    "                'l1' : {'x_offset': 2, \n",
    "                        'y_offset': 35,\n",
    "                        'text_font_size': \"18pt\",\n",
    "                        'text_baseline': \"top\",\n",
    "                        'text_color': 'black'\n",
    "                        },\n",
    "        },            \n",
    "\n",
    "        'number_of_workers':{\n",
    "            'block':{'line_width': 10, \n",
    "                        'line_color': 'white', \n",
    "                        'fill_alpha': 0.80, \n",
    "                        'palette': palette},\n",
    "            'l2' : {'x_offset': 8, \n",
    "                    'y_offset': -15,\n",
    "                    'text_font_size': \"24pt\",\n",
    "                    'text_baseline': \"top\",\n",
    "                    'text_color': 'black'\n",
    "                    },\n",
    "            'l1' : {'x_offset': 8, \n",
    "                    'y_offset': 4,\n",
    "                    'text_font_size': \"18pt\",\n",
    "                    'text_baseline': \"top\",\n",
    "                    'text_color': 'white'\n",
    "                    },\n",
    "        },\n",
    "        \n",
    "        'number_of_students':{\n",
    "                'block':{'line_width': 10, \n",
    "                         'line_color': 'white', \n",
    "                         'fill_alpha': 0.80, \n",
    "                         'palette': palette},\n",
    "                'l2' : {'x_offset': 10, \n",
    "                        'y_offset': -35,\n",
    "                        'text_font_size': \"30pt\",\n",
    "                        'text_baseline': \"top\",\n",
    "                        'text_color': 'black'\n",
    "                        },\n",
    "                'l1' : {'x_offset': 10, \n",
    "                        'y_offset': 4,\n",
    "                        'text_font_size': \"18pt\",\n",
    "                        'text_baseline': \"top\",\n",
    "                        'text_color': 'white'\n",
    "                        },\n",
    "        },\n",
    "    }\n",
    "        \n",
    "    return label_offset_dict[metric] if metric in label_offset_dict.keys() else label_offset_dict[metric]['default']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  -  ('#00204C', '#00204E', '#002150', '#414D6B', '#424E6B', '#434E6B', '#7C7B78', '#7D7C78', '#7E7D78', '#BDAF6E', '#BEB06E', '#BFB16D', '#FFE642', '#FFE743', '#FFE844')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"cee05fb9-0fcb-4d51-994f-bb7fe43d0cdf\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"cee05fb9-0fcb-4d51-994f-bb7fe43d0cdf\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"cee05fb9-0fcb-4d51-994f-bb7fe43d0cdf\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2008a32b07146bd8f4fa1f0c37e7f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(render_bundle={'docs_json': {'42466ebc-dc9a-4d5c-bcf6-d95a40500251': {'version': '3.4.3', 'title': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l2</th>\n",
       "      <th>number_of_workers_all_sum</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>dx</th>\n",
       "      <th>dy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Professional | 24%</td>\n",
       "      <td>26566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>824.839801</td>\n",
       "      <td>664.327154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business | 17%</td>\n",
       "      <td>18422</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>664.327154</td>\n",
       "      <td>824.839801</td>\n",
       "      <td>460.672846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Office Admin | 13%</td>\n",
       "      <td>13832</td>\n",
       "      <td>824.839801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>431.946316</td>\n",
       "      <td>660.511906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sales | 9%</td>\n",
       "      <td>9727</td>\n",
       "      <td>824.839801</td>\n",
       "      <td>660.511906</td>\n",
       "      <td>431.946316</td>\n",
       "      <td>464.488094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Production | 7%</td>\n",
       "      <td>7472</td>\n",
       "      <td>1256.786117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>384.923694</td>\n",
       "      <td>400.394094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistics | 6%</td>\n",
       "      <td>6955</td>\n",
       "      <td>1641.709811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>358.290189</td>\n",
       "      <td>400.394094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Construction | 5%</td>\n",
       "      <td>5721</td>\n",
       "      <td>1256.786117</td>\n",
       "      <td>400.394094</td>\n",
       "      <td>285.341299</td>\n",
       "      <td>413.554508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Facilities | 4%</td>\n",
       "      <td>4303</td>\n",
       "      <td>1256.786117</td>\n",
       "      <td>813.948602</td>\n",
       "      <td>285.341299</td>\n",
       "      <td>311.051398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Food | 4%</td>\n",
       "      <td>4124</td>\n",
       "      <td>1542.127416</td>\n",
       "      <td>400.394094</td>\n",
       "      <td>244.372530</td>\n",
       "      <td>348.090136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Maint | 3%</td>\n",
       "      <td>3603</td>\n",
       "      <td>1786.499945</td>\n",
       "      <td>400.394094</td>\n",
       "      <td>213.500055</td>\n",
       "      <td>348.090136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Security | 3%</td>\n",
       "      <td>2728</td>\n",
       "      <td>1542.127416</td>\n",
       "      <td>748.484230</td>\n",
       "      <td>282.404065</td>\n",
       "      <td>199.250246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Personal Care | 2%</td>\n",
       "      <td>2427</td>\n",
       "      <td>1542.127416</td>\n",
       "      <td>947.734476</td>\n",
       "      <td>282.404065</td>\n",
       "      <td>177.265524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Health | 2%</td>\n",
       "      <td>2394</td>\n",
       "      <td>1824.531480</td>\n",
       "      <td>748.484230</td>\n",
       "      <td>175.468520</td>\n",
       "      <td>281.417032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Natural | 1%</td>\n",
       "      <td>809</td>\n",
       "      <td>1824.531480</td>\n",
       "      <td>1029.901262</td>\n",
       "      <td>175.468520</td>\n",
       "      <td>95.098738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    l2  number_of_workers_all_sum            x            y  \\\n",
       "0   Professional | 24%                      26566     0.000000     0.000000   \n",
       "1       Business | 17%                      18422     0.000000   664.327154   \n",
       "2   Office Admin | 13%                      13832   824.839801     0.000000   \n",
       "3           Sales | 9%                       9727   824.839801   660.511906   \n",
       "4      Production | 7%                       7472  1256.786117     0.000000   \n",
       "5       Logistics | 6%                       6955  1641.709811     0.000000   \n",
       "6    Construction | 5%                       5721  1256.786117   400.394094   \n",
       "7      Facilities | 4%                       4303  1256.786117   813.948602   \n",
       "8            Food | 4%                       4124  1542.127416   400.394094   \n",
       "9           Maint | 3%                       3603  1786.499945   400.394094   \n",
       "10       Security | 3%                       2728  1542.127416   748.484230   \n",
       "11  Personal Care | 2%                       2427  1542.127416   947.734476   \n",
       "12         Health | 2%                       2394  1824.531480   748.484230   \n",
       "13        Natural | 1%                        809  1824.531480  1029.901262   \n",
       "\n",
       "            dx          dy  \n",
       "0   824.839801  664.327154  \n",
       "1   824.839801  460.672846  \n",
       "2   431.946316  660.511906  \n",
       "3   431.946316  464.488094  \n",
       "4   384.923694  400.394094  \n",
       "5   358.290189  400.394094  \n",
       "6   285.341299  413.554508  \n",
       "7   285.341299  311.051398  \n",
       "8   244.372530  348.090136  \n",
       "9   213.500055  348.090136  \n",
       "10  282.404065  199.250246  \n",
       "11  282.404065  177.265524  \n",
       "12  175.468520  281.417032  \n",
       "13  175.468520   95.098738  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from squarify import normalize_sizes, squarify\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "from bokeh.sampledata.sample_superstore import data\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.io import output_notebook\n",
    "from jupyter_bokeh.widgets import BokehModel # widgets third party extension will be required\n",
    "from bokeh.transform import linear_cmap\n",
    "from bokeh.models import CrosshairTool, Span, NumeralTickFormatter, HoverTool, CustomJS, Slider, ColumnDataSource\n",
    "\n",
    "\n",
    "df_occupation_level_mapping = pd.read_excel('../assets/bls_cpsaat39_2011_to_2015.xlsx', sheet_name='level_mapping_l0', header=0)\n",
    "df_occupation_level_mapping_distinct = df_occupation_level_mapping[['l4', 'l3', 'l2', 'l1']].drop_duplicates().reset_index()\n",
    "df_occupation_level_mapping_distinct = df_occupation_level_mapping_distinct[['l4', 'l3', 'l2', 'l1']]\n",
    "df_occupation_level_mapping_distinct\n",
    "\n",
    "# metric = 'number_of_students_women_sum'\n",
    "metric = 'number_of_workers_all_sum'\n",
    "base_metric = metric.replace('_sum', '').replace('_women', '').replace('_men', '').replace('_all', '')\n",
    "\n",
    "l1_grouping = df_level_list[0]\n",
    "l2_grouping = df_level_list[1]\n",
    "\n",
    "l1_grouping = pd.merge(l1_grouping,\n",
    "                        df_occupation_level_mapping_distinct[['l1', 'l2']], \n",
    "                        how='left',\n",
    "                        left_on=['l1'],\n",
    "                        right_on=['l1'])\n",
    "\n",
    "\n",
    "l1_grouping = l1_grouping[l1_grouping['year'] == '2015']\n",
    "l1_grouping = l1_grouping[['l1','l2', metric]]\n",
    "l2_grouping = l2_grouping[l2_grouping['year'] == '2015']\n",
    "l2_grouping = l2_grouping[['l2', metric]]\n",
    "\n",
    "short_name_l2 = get_short_names('l2', base_metric)\n",
    "l1_grouping['l2'] = l1_grouping['l2'].apply(lambda x: short_name_l2[x] if x in short_name_l2.keys() else x)\n",
    "l2_grouping['l2'] = l2_grouping['l2'].apply(lambda x: short_name_l2[x] if x in short_name_l2.keys() else x)\n",
    "\n",
    "short_name_l1 = get_short_names('l1', base_metric)\n",
    "l1_grouping['l1'] = l1_grouping['l1'].apply(lambda x: short_name_l1[x] if x in short_name_l1.keys() else x)\n",
    "\n",
    "\n",
    "total = l2_grouping[metric].sum() # total seems low, validate later on\n",
    "\n",
    "l1_grouping['l1'] = l1_grouping.apply(lambda x: x['l1'] + ' | ' + str(int(round(x[metric]/total*100, 0))) + '%', axis=1)\n",
    "l2_grouping['l2'] = l2_grouping.apply(lambda x: x['l2'] + ' | ' + str(int(round(x[metric]/total*100, 0))) + '%', axis=1)\n",
    "l2_lookup = {k: k + \" | \" + v for k, v in (x.split(\" | \") for x in l2_grouping['l2'].to_list())}\n",
    "l1_grouping['l2'] = l1_grouping.apply(lambda x: l2_lookup[x['l2']], axis=1)\n",
    "\n",
    "# l1_grouping\n",
    "\n",
    "\n",
    "\n",
    "# keep only records with non-zero values, otherwise treemap will throw a divide by zero error\n",
    "l1_grouping = l1_grouping[l1_grouping[metric] > 0]\n",
    "l2_grouping = l2_grouping[l2_grouping[metric] > 0]\n",
    "\n",
    "def treemap(df, col, x, y, dx, dy, *, N=100):\n",
    "    sub_df = df.nlargest(N, col)\n",
    "    normed = normalize_sizes(sub_df[col], dx, dy)\n",
    "    blocks = squarify(normed, x, y, dx, dy)\n",
    "    blocks_df = pd.DataFrame.from_dict(blocks).set_index(sub_df.index)\n",
    "    return sub_df.join(blocks_df, how='left').reset_index()\n",
    "\n",
    "\n",
    "# for sex in ['women','men','all']:\n",
    "#     if sex in metric:\n",
    "#         l2_grouping['l2'] = l2_grouping['l2'].apply(lambda x: x + ' ' + sex.title()) \n",
    "#         break\n",
    "\n",
    "# for sex in ['women','men','all']:\n",
    "#     if sex in metric:\n",
    "#         l1_grouping['l2'] = l1_grouping['l2'].apply(lambda x: x + ' ' + sex.title()) \n",
    "#         break\n",
    "\n",
    "\n",
    "l2s = tuple(l2_grouping['l2'].unique().tolist())\n",
    "\n",
    "\n",
    "x, y, w, h = 0, 0, 2000, 1125\n",
    "blocks_by_L2 = treemap(l2_grouping, metric, x, y, w, h)\n",
    "\n",
    "blocks_by_L2.drop(columns=['index'], inplace=True)\n",
    "\n",
    "blocks_by_L2 = blocks_by_L2[['l2', metric, 'x', 'y', 'dx', 'dy']] \n",
    "\n",
    "dfs = []\n",
    "for index, (l2, number_of_workers_all, x, y, dx, dy) in blocks_by_L2.iterrows():\n",
    "    df = l1_grouping[l1_grouping.l2==l2]    \n",
    "    dfs.append(treemap(df, metric, x, y, dx, dy, N=100))\n",
    "\n",
    "blocks = pd.concat(dfs)\n",
    "\n",
    "\n",
    "p = figure(width=w, height=h, tooltips=\"@l1\", toolbar_location=None,\n",
    "           x_axis_location=None, y_axis_location=None)\n",
    "p.x_range.range_padding = p.y_range.range_padding = 0\n",
    "p.grid.grid_line_color = None\n",
    "\n",
    "\n",
    "# Get treemap format parameters\n",
    "param_set = get_format_parameters(metric=base_metric, number_of_groups=len(l2_grouping))\n",
    "block_params = param_set['block']\n",
    "l2_params = param_set['l2']\n",
    "l1_params = param_set['l1']\n",
    "\n",
    "p.block('x', 'y', 'dx', 'dy', source=blocks, line_width=block_params['line_width'], line_color=block_params['line_color'],\n",
    "        fill_alpha=block_params['fill_alpha'], fill_color=factor_cmap(\"l2\", block_params['palette'][::-1] if 'women' in metric else block_params['palette'], l2s)) #legend_field=\"l2\",\n",
    "\n",
    "p.text('x', 'y',  x_offset=l2_params['x_offset'], y_offset=l2_params['y_offset'], text=\"l2\", source=blocks_by_L2,\n",
    "       text_font_size=l2_params['text_font_size'], text_color=l2_params['text_color'])\n",
    "\n",
    "blocks[\"ytop\"] = blocks.y + blocks.dy\n",
    "\n",
    "p.text('x', 'ytop', x_offset=l1_params['x_offset'], y_offset=l1_params['y_offset'], text=\"l1\", source=blocks,\n",
    "       text_font_size=l1_params['text_font_size'], text_baseline=l1_params['text_baseline'],\n",
    "       text_color=l1_params['text_color'])\n",
    "\n",
    "# p.legend.title = \"L2 Grouping\"\n",
    "# p.legend.label_text_font_size = \"10pt\"\n",
    "# p.legend.location = \"top_right\"\n",
    "# p.legend.orientation = \"vertical\"\n",
    "\n",
    "\n",
    "# Generate color band\n",
    "# y = l2_grouping[metric]\n",
    "# cmap = linear_cmap(field_name='y', palette=get_palette(len(l2_grouping)), low=min(y), high=max(y))\n",
    "# r = p.scatter(l2_grouping['l2'], y, color=cmap, size=25, legend_label='Occupation')\n",
    "# color_bar = r.construct_color_bar(width=10) #, formatter=NumeralTickFormatter(format=\"0,0\")\n",
    "# p.add_layout(color_bar, 'right')    \n",
    "\n",
    "output_notebook()\n",
    "handle = display(BokehModel(p))\n",
    "blocks\n",
    "\n",
    "blocks_by_L2\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
